\documentclass[12pt,titlepage=true]{article}

\input{input/package}

\usepackage{xcolor}
\usepackage{dsfont}
%\usepackage{layout}
%\usepackage{rowcolor}
\definecolor{bleuX}{RGB}{0,62,92}
\renewcommand{\arraystretch}{1.3}
\renewcommand\labelitemi{\textbullet}
\input{input/meptex}

\newcommand{\esp}{\mathbb{E}}
\renewcommand{\exp}{\mathrm{e}^}
\renewcommand{\P}{\mathbb{P}}


\title{Vitesse d'invasion pour un modèle de reproduction et dispersion}
\author{Augustin Lenormand \and Basile Bruneau}

\begin{document}
\maketitle

\section{Grandes déviations d'une marche aléatoire}
	\subsection{}
	\renewcommand\labelitemi{\textbullet}
	\begin{itemize}
	
	\item	Soit $\alpha\in [0,1]$ et $\lambda_1, \lambda_2$ dans $\mathbb{R}$.
	
			\begin{IEEEeqnarray*}{l C c}
				\esp( \exp{(\alpha \lambda_1 + (1 - \alpha)\lambda_2) X}) & = &  \esp((\exp{\lambda_1 X})^{\alpha}(\exp{\lambda_2 X})^{1-\alpha}\\
												   					  & \leqslant & (\esp(\exp{\lambda_1 X}))^{\alpha} (\esp(\exp{\lambda_2 X}))^{1- \alpha}
			\end{IEEEeqnarray*}
	
	
			Ici la dernière inégalité est l'inégalité de Hölder. En passant au logarithme il vient donc naturellement :	
	
			\begin{equation*}
				\Lambda((\alpha \lambda_1 + (1 - \alpha)\lambda_2) X) \leqslant \alpha \Lambda(\lambda_1 X) + (1-\alpha) \Lambda(\lambda_2 X)
			\end{equation*}
		
			\fbox{Donc $\Lambda$ est convexe.}
		
	\item	De même les fonctions $f_\lambda$ telles que $f_\lambda (x)=\lambda x - \Lambda (\lambda)$ sont toutes convexes. 
			Donc par définition leurs épigraphes sont convexes.
		
			Or l'épigraphe du supremum pour $\lambda$ dans $\mathbb{R}$ de ces fonctions est l'intersection des épigraphes de toutes ces fonctions. Comme intersection d'ensemble convexes , il est donc convexe lui aussi. Donc l'épigraphe de $\Psi$ est convexe.
		
			\fbox{Donc $\Psi$ est convexe.}

	\item	$\Lambda(0)=0$ donc :
			\begin{equation*}
			\forall x \in \mathbb{R}, \sup_{\lambda \in \mathbb{R}}(\lambda x - \Lambda(\lambda)) \geqslant 0\cdotp x - \Lambda(0) = 0
			\end{equation*}	
			\underline{Donc $\Psi\geqslant0$.}
			
			Soit $\lambda$ dans $\mathbb{R}$.
			\begin{equation*}
			\exp{f_\lambda(m))}=\frac{\exp{\lambda \esp(X)}}{\esp(\exp{\lambda X})}
			\end{equation*}			
			Or la fonction $x \mapsto \exp{\lambda x}$ est convexe, donc d'après l'inégalité de Jensen,	$\exp{\lambda \esp(X)}\leqslant\esp(\exp{\lambda X})$. Ainsi $\exp{f_\lambda(m))}\leqslant 1$ et $\lambda \esp(X) - \Lambda(\lambda)\leqslant 0$. 
			
			Donc $\Psi(\esp(X))\leqslant0$. Or $\Psi\geqslant0$.
			
			\fbox{Donc $\Psi$ admet un minimum en $m$ et $\Psi(m)=0$.}

	\item	Soit $x\geqslant m$ et $\lambda <0$. Alors on peut écrire :
			\begin{IEEEeqnarray*}{C}
			\lambda x -\Lambda(\lambda) \leqslant \lambda m - \Lambda(\lambda) = 0\\
			\lambda x -\Lambda(\lambda) \leqslant0 \leqslant\sup_{\lambda \in \mathbb{R}}\{\lambda x - \Lambda(\lambda)\}
			\end{IEEEeqnarray*}
			
			\fbox{Donc prendre le supremum des $f_\lambda$ pour $\lambda\geqslant0$ est suffisant pour définir $\Psi$}
			

	\end{itemize}
		 
	\subsection{}
	
	\begin{IEEEeqnarray*}{cCc}
		\P(S_n \geqslant nx) & = & \esp(\mathds{1}_{S_n-nx\geqslant0})
	\end{IEEEeqnarray*}
	
	Comme $S_n-nx\geqslant0$ alors pour tout $\lambda$ positif, $\exp{\lambda (S_n-nx)}\geqslant1$ et

	\begin{equation*}
		\esp(\mathds{1}_{S_n-nx\geqslant0}) \leqslant \esp(\exp{\lambda (S_n-nx)}\mathds{1}_{S_n-nx\geqslant0}) \leqslant \esp(\exp{\lambda (S_n - x)})
	\end{equation*}
	On a donc :
	\begin{equation*}
	\P(S_n \geqslant nx) \leqslant \exp{-\lambda n x}\esp(\exp{\lambda S_n})
	\end{equation*}
	Comme les variables $(X_i)_{i\in\llbracket 1,n\rrbracket}$ sont des v.a indépendantes de même loi on peut écrire que $\esp(\exp{\lambda S_n})=(\esp(\exp{\lambda X}))^n=\exp{n\Lambda(\lambda)}$.
	
	Par le calcul on obtient alors :
	\begin{IEEEeqnarray*}{ccCcc}
		\P(S_n \geqslant nx) && \leqslant &&  \exp{-\lambda n x}\exp{n\Lambda(\lambda)} \\
		\log \P(S_n \geqslant nx) && \leqslant && -\lambda n x + n\Lambda(\lambda) \\
		-\frac{1}{n} \log \P(S_n \geqslant nx) && \geqslant && \lambda  x -\Lambda(\lambda) \IEEEyesnumber \label{IneQ2}\\
	\end{IEEEeqnarray*}
	
	\ref{IneQ2} est vrai pour tout $\lambda$ positif et pour tout $n$. Donc le passage au supremum pour $\lambda$ positif et à la limite inférieure pour $n$ est possible et ne modifie pas l'inégalité.
	
	On obtient bien alors :
	\begin{equation}
	\boxed{\liminf_{n\rightarrow\infty}-\frac{1}{n} \log \P(S_n \geqslant nx)\geqslant\sup_{\lambda\geqslant0}\{\lambda x - \Lambda(\lambda)\}}
	\end{equation}
	
\end{document}